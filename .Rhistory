m
t.points
var.u0
sensitivity
log.grow
var.u1
eff.sizes
N <- list()
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
while(condition == F){
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(results$prop_simplified * 100)))
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == Nmin+1 | Nmax == Nmin) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f)\n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
N_max
_max=1000
N_min=30
tol
tol=.001
while(condition == F){
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(results$prop_simplified * 100)))
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == Nmin+1 | Nmax == Nmin) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f)\n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
N
j
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
N <- list()
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
_max=1000
N_max=1000
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
while(condition == F){
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(results$prop_simplified * 100)))
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == Nmin+1 | Nmax == Nmin) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f)\n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
start_time <- Sys.time()
if(!is.null(seed)) {set.seed(seed)}  # set user-specified seed for reproducibility
N <- list()
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
while(condition == F){
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(results$prop_simplified * 100)))
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == Nmin+1 | Nmax == Nmin) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f)\n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
m
m <- 1000
start_time <- Sys.time()
if(!is.null(seed)) {set.seed(seed)}  # set user-specified seed for reproducibility
N <- list()
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
while(condition == F){
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(results$prop_simplified * 100)))
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == Nmin+1 | Nmax == Nmin) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f)\n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
library(BayeSSD)
BayeSSD(eta = .8,
hypothesis = list("a=b=c"),
attrition = "nonparametric",
params = c(1,.799,.465),
m=1000,
t.points = c(0,4,8),
var.u0 =  1.854005,
var.u1 = 0.1265689,
var.e = 0.372619,
cov = -0.3485869,
eff.sizes = c(0.1624624, -0.0862778, -0.230364),
BFthres = 5,
fraction = 1,
sensitivity = F,
N_max = 2000,
method = "bfc")
BayeSSD(eta = .8,
hypothesis = list("a=b=c"),
attrition = "nonparametric",
params = c(1,.799,.465),
m=1000,
t.points = c(0,4,8),
var.u0 =  1.854005,
var.u1 = 0.1265689,
var.e = 0.372619,
cov = -0.3485869,
eff.sizes = c(0.1624624, -0.0862778, -0.230364),
BFthres = 5,
fraction = 1,
sensitivity = F,
N_max = 2000,
method = "bfc")
BayeSSD(eta = .8,
hypothesis = list("a=b=c"),
attrition = "nonparametric",
params = c(1,.799,.465),
m=1000,
t.points = c(0,4,8),
var.u0 =  1.854005,
var.u1 = 0.1265689,
var.e = 0.372619,
cov = -0.3485869,
eff.sizes = c(0.1624624, -0.0862778, -0.230364),
BFthres = 5,
fraction = 1,
sensitivity = F,
N_max = 2000,
method = "bfc")
library(BayeSSD)
BayeSSD(eta = .8,
hypothesis = list("a=b=c"),
attrition = "nonparametric",
params = c(1,.799,.465),
m=1000,
t.points = c(0,4,8),
var.u0 =  1.854005,
var.u1 = 0.1265689,
var.e = 0.372619,
cov = -0.3485869,
eff.sizes = c(0.1624624, -0.0862778, -0.230364),
BFthres = 5,
fraction = 1,
sensitivity = F,
N_max = 2000,
method = "bfc")
devtools::document()
devtools::document()
BayeSSD(m=10)
library(BayeSSD)
BayeSSD(m=10)
library(BayeSSD)
BayeSSD(m=10)
library(BayeSSD)
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition/too few observations",
results$prop_simplified * 100))
results <- list(prop_simplified=.5)
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition/too few observations",
results$prop_simplified * 100))
getpower()
library(BayeSSD)
getpower()
getpower_mis_mv()
getpower_mis_mv(params=c(.9,1))
results <- getpower_mis_mv(params=c(.9,1))
results
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition/too few observations",
results$prop_simplified * 100))
}
BayeSSD(eta = .8,
hypothesis = list("a>b>c"),
attrition = "nonparametric",
params = c(1,.799,.465),
m=5000,
t.points = c(0,4,8),
var.u0 = var_intercept,
var.u1 = var_slope,
var.e = var_resid,
cov = cov_int_slope,
eff.sizes = c(delta_cond1, delta_cond2, delta_cond3),
BFthres = 10,
fraction = 1,
sensitivity = F,
N_max = 1500,
method = "bfc")
library(BayeSSD)
eta=.8
attrition="weibull"
params=c(.5,1)
m=100
t.points=c(0,1,2,3,4)
var.u0=0.01
var.u1=.1
var.e=.01
cov=0
eff.sizes=c(0, .5, .8)
BFthres=5
fraction=1
log.grow=F
seed=NULL
seed=NULL
hypothesis="a<b<c"
PMPthres=.9
sensitivity=F
tol=.001
N_max=1000
N_min=30
method="bfc"
N <- list()
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
results
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
results
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
library(BayeSSD)
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
results
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition/too few observations",
results$prop_simplified * 100))
}
print(results$prop_simplified)
print(class(results$prop_simplified))
print(str(results$prop_simplified))
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%.0f%% of models required simplification (independent random effects) due to high attrition/too few observations",
results$prop_simplified * 100))
}
library(BayeSSD)
