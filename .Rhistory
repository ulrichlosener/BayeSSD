suppressWarnings(dat$mis <- rbinom(n = nrow(dat), size = 1, prob = dat$hazard)) # suppress warning about NAs being produced
dat$mis <- unsplit(lapply(split(dat$mis, dat$id), function(x) {
if (any(x == 1, na.rm = TRUE)) {
first_mis <- which(x == 1)[1]  # Get first occurrence of 1
x[first_mis:length(x)] <- 1    # Set all subsequent to 1
}
x[is.na(x)] <- 0  # Treat NAs as 0 (non-missing)
x
}), dat$id)
dat$y[dat$mis == 1] <- NA
} else {
dat <- data.frame(dat0, y)
}
simplified <- F
model <- tryCatch({
# First try to fit full model
lme4::lmer(formula = y ~ t + treat + t:treat + (1 + t | id),
data = dat,
REML = F,
control = lme4::lmerControl(calc.derivs = F))
}, error = function(e) {
if (grepl("number of observations.*number of random effects", e$message)) {
simplified <<- TRUE
# If too little observations, try uncorrelated random effects
tryCatch({
lme4::lmer(formula = y ~ t + treat + t:treat + (1 | id) + (0 + t | id),
data = dat,
REML = F,
control = lme4::lmerControl(calc.derivs = F))
})
}
})
# In case of rank deficiency due to too little observations, throw error
if(length(model@beta) < 6) {stop("It seems that due to the high attrition rate, the fixed-effects model matrix of the multilevel model has become rank deficient. Consider lowering the attrition rate.")}
# extract estim
n <- length(t.points)  # number of measurement occasions
# create time variable t
if(log.grow==F) {t <- rep(t.points, N) # if logarithmic growth is used, take log of t.points
} else {if(min(t.points)==0) {t <- rep(log(t.points+1), N)} else {t <- rep(log(t.points), N)} # if the first timepoint is zero, we add 1 to all timepoints because log(0) is undefined
}
t.prop <- t.points/max(t.points) # create rescaled time variable (from 0 to 1)
id <- rep(seq_len(N), each=n)  # create ID variable
treat <- as.character(gl(n=3, k=n, length=N*n, labels=c("a","b","c"))) # create treatment variable
dat0 <- data.frame(id, treat, t) # combine into data frame
dat0$treat <- factor(dat0$treat, levels = c("a", "b", "c")) # Forces "a" as reference
multinorm <- MASS::mvrnorm(n=2*N, mu=c(0,0), matrix(c(var.u0, cov, cov, var.u1), nrow=2, ncol=2)) # draw random effects
# make params into list of one vector
if (is.list(params)) {
params <- list(unlist(params, use.names = FALSE))
} else {
params <- list(params)
}
# Compute survival curves
if(any(attrition != F)){
surviv <- survival(attrition, params, t.points)
shifted_surviv <- lapply(surviv, function(x) {c(x[-1], NA)}) # drop first element and append NA to compute hazard
} else if(attrition==F){
surviv <- list(rep(1, n))
shifted_surviv <- c(surviv[-1], NA)
}
# compute hazard: (S_t - S_{t+1}) / S_t
hazard <- mapply(function(a, b) {(a - b) / a},
surviv,
shifted_surviv,
SIMPLIFY = FALSE)
# generate data under the research hypothesis
u0 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),1], each=n) # random intercepts
u1 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),2], each=n) # random slopes
e <- rnorm(N*n, 0, sqrt(var.e)) # error variance for H1
# Create treatment dummy variables
treat_TAU <- as.numeric(treat == "b")
treat_INT <- as.numeric(treat == "c")
beta1_WL <- unlist(eff.sizes[1]) * sqrt(var.u1)
beta2_TAU <- unlist(eff.sizes[2]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for b from effect size
beta3_INT <- unlist(eff.sizes[3]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for c from effect size
y <- beta1_WL*t + u0 + beta2_TAU*treat_TAU*t + beta3_INT*treat_INT*t + u1*t + e # create outcome variable y
if(attrition != F) {
dat <- data.frame(dat0, y, hazard = unlist(hazard))
suppressWarnings(dat$mis <- rbinom(n = nrow(dat), size = 1, prob = dat$hazard)) # suppress warning about NAs being produced
dat$mis <- unsplit(lapply(split(dat$mis, dat$id), function(x) {
if (any(x == 1, na.rm = TRUE)) {
first_mis <- which(x == 1)[1]  # Get first occurrence of 1
x[first_mis:length(x)] <- 1    # Set all subsequent to 1
}
x[is.na(x)] <- 0  # Treat NAs as 0 (non-missing)
x
}), dat$id)
dat$y[dat$mis == 1] <- NA
} else {
dat <- data.frame(dat0, y)
}
simplified <- F
model <- tryCatch({
# First try to fit full model
lme4::lmer(formula = y ~ t + treat + t:treat + (1 + t | id),
data = dat,
REML = F,
control = lme4::lmerControl(calc.derivs = F))
}, error = function(e) {
if (grepl("number of observations.*number of random effects", e$message)) {
simplified <<- TRUE
# If too little observations, try uncorrelated random effects
tryCatch({
lme4::lmer(formula = y ~ t + treat + t:treat + (1 | id) + (0 + t | id),
data = dat,
REML = F,
control = lme4::lmerControl(calc.derivs = F))
})
}
})
# In case of rank deficiency due to too little observations, throw error
if(length(model@beta) < 6) {stop("It seems that due to the high attrition rate, the fixed-effects model matrix of the multilevel model has become rank deficient. Consider lowering the attrition rate.")}
# extract estim
params <- list(.99,1)
n <- length(t.points)  # number of measurement occasions
# create time variable t
if(log.grow==F) {t <- rep(t.points, N) # if logarithmic growth is used, take log of t.points
} else {if(min(t.points)==0) {t <- rep(log(t.points+1), N)} else {t <- rep(log(t.points), N)} # if the first timepoint is zero, we add 1 to all timepoints because log(0) is undefined
}
t.prop <- t.points/max(t.points) # create rescaled time variable (from 0 to 1)
id <- rep(seq_len(N), each=n)  # create ID variable
treat <- as.character(gl(n=3, k=n, length=N*n, labels=c("a","b","c"))) # create treatment variable
dat0 <- data.frame(id, treat, t) # combine into data frame
dat0$treat <- factor(dat0$treat, levels = c("a", "b", "c")) # Forces "a" as reference
multinorm <- MASS::mvrnorm(n=2*N, mu=c(0,0), matrix(c(var.u0, cov, cov, var.u1), nrow=2, ncol=2)) # draw random effects
# make params into list of one vector
if (is.list(params)) {
params <- list(unlist(params, use.names = FALSE))
} else {
params <- list(params)
}
# Compute survival curves
if(any(attrition != F)){
surviv <- survival(attrition, params, t.points)
shifted_surviv <- lapply(surviv, function(x) {c(x[-1], NA)}) # drop first element and append NA to compute hazard
} else if(attrition==F){
surviv <- list(rep(1, n))
shifted_surviv <- c(surviv[-1], NA)
}
# compute hazard: (S_t - S_{t+1}) / S_t
hazard <- mapply(function(a, b) {(a - b) / a},
surviv,
shifted_surviv,
SIMPLIFY = FALSE)
# generate data under the research hypothesis
u0 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),1], each=n) # random intercepts
u1 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),2], each=n) # random slopes
e <- rnorm(N*n, 0, sqrt(var.e)) # error variance for H1
# Create treatment dummy variables
treat_TAU <- as.numeric(treat == "b")
treat_INT <- as.numeric(treat == "c")
beta1_WL <- unlist(eff.sizes[1]) * sqrt(var.u1)
beta2_TAU <- unlist(eff.sizes[2]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for b from effect size
beta3_INT <- unlist(eff.sizes[3]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for c from effect size
y <- beta1_WL*t + u0 + beta2_TAU*treat_TAU*t + beta3_INT*treat_INT*t + u1*t + e # create outcome variable y
if(attrition != F) {
dat <- data.frame(dat0, y, hazard = unlist(hazard))
suppressWarnings(dat$mis <- rbinom(n = nrow(dat), size = 1, prob = dat$hazard)) # suppress warning about NAs being produced
dat$mis <- unsplit(lapply(split(dat$mis, dat$id), function(x) {
if (any(x == 1, na.rm = TRUE)) {
first_mis <- which(x == 1)[1]  # Get first occurrence of 1
x[first_mis:length(x)] <- 1    # Set all subsequent to 1
}
x[is.na(x)] <- 0  # Treat NAs as 0 (non-missing)
x
}), dat$id)
dat$y[dat$mis == 1] <- NA
} else {
dat <- data.frame(dat0, y)
}
simplified <- F
model <- tryCatch({
# First try to fit full model
lme4::lmer(formula = y ~ t + treat + t:treat + (1 + t | id),
data = dat,
REML = F,
control = lme4::lmerControl(calc.derivs = F))
}, error = function(e) {
if (grepl("number of observations.*number of random effects", e$message)) {
simplified <<- TRUE
# If too little observations, try uncorrelated random effects
tryCatch({
lme4::lmer(formula = y ~ t + treat + t:treat + (1 | id) + (0 + t | id),
data = dat,
REML = F,
control = lme4::lmerControl(calc.derivs = F))
})
}
})
# In case of rank deficiency due to too little observations, throw error
if(length(model@beta) < 6) {stop("It seems that due to the high attrition rate, the fixed-effects model matrix of the multilevel model has become rank deficient. Consider lowering the attrition rate.")}
# extract estim
params <- list(.8,1)
getbf_mis_mv <- function(N=100, attrition="weibull", params=list(.8,1), hypothesis=list("a<b<c","a=b=c"),
t.points=c(0,1,2), var.u0=.01, var.u1=.01, cov=0, var.e=.01, eff.sizes=c(0, .5, .8),
fraction=1, log.grow=F){
n <- length(t.points)  # number of measurement occasions
# create time variable t
if(log.grow==F) {t <- rep(t.points, N) # if logarithmic growth is used, take log of t.points
} else {if(min(t.points)==0) {t <- rep(log(t.points+1), N)} else {t <- rep(log(t.points), N)} # if the first timepoint is zero, we add 1 to all timepoints because log(0) is undefined
}
t.prop <- t.points/max(t.points) # create rescaled time variable (from 0 to 1)
id <- rep(seq_len(N), each=n)  # create ID variable
treat <- as.character(gl(n=3, k=n, length=N*n, labels=c("a","b","c"))) # create treatment variable
dat0 <- data.frame(id, treat, t) # combine into data frame
dat0$treat <- factor(dat0$treat, levels = c("a", "b", "c")) # Forces "a" as reference
multinorm <- MASS::mvrnorm(n=2*N, mu=c(0,0), matrix(c(var.u0, cov, cov, var.u1), nrow=2, ncol=2)) # draw random effects
# make params into list of one vector
if (is.list(params)) {
params <- list(unlist(params, use.names = FALSE))
} else {
params <- list(params)
}
# Compute survival curves
if(any(attrition != F)){
surviv <- survival(attrition, params, t.points)
shifted_surviv <- lapply(surviv, function(x) {c(x[-1], NA)}) # drop first element and append NA to compute hazard
} else if(attrition==F){
surviv <- list(rep(1, n))
shifted_surviv <- c(surviv[-1], NA)
}
# compute hazard: (S_t - S_{t+1}) / S_t
hazard <- mapply(function(a, b) {(a - b) / a},
surviv,
shifted_surviv,
SIMPLIFY = FALSE)
# generate data under the research hypothesis
u0 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),1], each=n) # random intercepts
u1 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),2], each=n) # random slopes
e <- rnorm(N*n, 0, sqrt(var.e)) # error variance for H1
# Create treatment dummy variables
treat_TAU <- as.numeric(treat == "b")
treat_INT <- as.numeric(treat == "c")
beta1_WL <- unlist(eff.sizes[1]) * sqrt(var.u1)
beta2_TAU <- unlist(eff.sizes[2]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for b from effect size
beta3_INT <- unlist(eff.sizes[3]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for c from effect size
y <- beta1_WL*t + u0 + beta2_TAU*treat_TAU*t + beta3_INT*treat_INT*t + u1*t + e # create outcome variable y
if(attrition != F) {
dat <- data.frame(dat0, y, hazard = unlist(hazard))
suppressWarnings(dat$mis <- rbinom(n = nrow(dat), size = 1, prob = dat$hazard)) # suppress warning about NAs being produced
dat$mis <- unsplit(lapply(split(dat$mis, dat$id), function(x) {
if (any(x == 1, na.rm = TRUE)) {
first_mis <- which(x == 1)[1]  # Get first occurrence of 1
x[first_mis:length(x)] <- 1    # Set all subsequent to 1
}
x[is.na(x)] <- 0  # Treat NAs as 0 (non-missing)
x
}), dat$id)
dat$y[dat$mis == 1] <- NA
} else {
dat <- data.frame(dat0, y)
}
simplified <- F
model <- tryCatch({
# First try to fit full model
lme4::lmer(formula = y ~ t + treat + t:treat + (1 + t | id),
data = dat,
REML = F,
control = lme4::lmerControl(calc.derivs = F))
}, error = function(e) {
if (grepl("number of observations.*number of random effects", e$message)) {
simplified <<- TRUE
# If too little observations, try uncorrelated random effects
tryCatch({
lme4::lmer(formula = y ~ t + treat + t:treat + (1 | id) + (0 + t | id),
data = dat,
REML = F,
control = lme4::lmerControl(calc.derivs = F))
})
}
})
# In case of rank deficiency due to too little observations, throw error
if(length(model@beta) < 6) {stop("It seems that due to the high attrition rate, the fixed-effects model matrix of the multilevel model has become rank deficient. Consider lowering the attrition rate.")}
# extract estimates from MLM
est <- model@beta[c(2,5,6)] # extract estimates of beta2 and beta3 under H0
names(est) <- c("a", "b", "c")
sig_WL <- as.matrix(vcov(model)[2,2])  # extract variance of estimates under H0
sig_TAU <- as.matrix(vcov(model)[5,5])  # extract variance of estimates under H0
sig_INT <- as.matrix(vcov(model)[6,6])  # extract variance of estimates under H0
# calculate N_eff
n_eff <- get_neff_mis_mv(model=model, N=N, t.points=t.points, surviv=surviv)
# evaluate hypotheses
hyp <- paste(hypothesis, collapse = ";")
n_hyp <- length(hypothesis)
bf_res <- bain::bain(x=est, Sigma=list(sig_WL, sig_TAU, sig_INT), n=unlist(n_eff),
hypothesis=hyp, group_parameters = 1, joint_parameters = 0)
bf_c <- bf_res[["fit"]][["BF.c"]][1]
PMPc <- bf_res[["fit"]][["PMPc"]][1]
bf12 <- NA
if(n_hyp==2){
bf12 <- bf_res[["BFmatrix"]][1,2]
}
return(output = list(bf_c=bf_c,
PMPc=PMPc,
bf12=bf12,
simplified=simplified,
oversimplified=oversimplified))
}
suppressWarnings({ # suppress warning "package 'future' was built under R version 4.4.3"
future::plan(future::multisession, workers = future::availableCores() - 1)  # Use all but one core
Ns <- rep(N, m)  # object to use lapply on with first argument for the function (N)
# Run simulation m times
bfs <- future.apply::future_lapply(
Ns,
function(ss){
getbf_mis_mv(ss,
attrition=attrition,
params=params, hypothesis=hypothesis, t.points=t.points,
var.u0=var.u0, var.u1=var.u1, cov=cov, var.e=var.e,
eff.sizes=eff.sizes, fraction=fraction, log.grow=log.grow)
},
future.seed = TRUE
)
future::plan(future::sequential)  # Reset plan to avoid unexpected parallel behavior later
})
bfs
bfs <- NULL
future::plan(future::sequential)  # Reset plan to avoid unexpected parallel behavior later
suppressWarnings({ # suppress warning "package 'future' was built under R version 4.4.3"
future::plan(future::multisession, workers = future::availableCores() - 1)  # Use all but one core
Ns <- rep(N, m)  # object to use lapply on with first argument for the function (N)
# Run simulation m times
bfs <- future.apply::future_lapply(
Ns,
function(ss){
getbf_mis_mv(ss,
attrition=attrition,
params=params, hypothesis=hypothesis, t.points=t.points,
var.u0=var.u0, var.u1=var.u1, cov=cov, var.e=var.e,
eff.sizes=eff.sizes, fraction=fraction, log.grow=log.grow)
},
future.seed = TRUE
)
future::plan(future::sequential)  # Reset plan to avoid unexpected parallel behavior later
})
future::plan(future::sequential)  # Reset plan to avoid unexpected parallel behavior later
suppressWarnings({ # suppress warning "package 'future' was built under R version 4.4.3"
future::plan(future::multisession, workers = future::availableCores() - 1)  # Use all but one core
Ns <- rep(N, m)  # object to use lapply on with first argument for the function (N)
# Run simulation m times
bfs <- future.apply::future_lapply(
Ns,
function(ss){
getbf_mis_mv(ss,
attrition=attrition,
params=params, hypothesis=hypothesis, t.points=t.points,
var.u0=var.u0, var.u1=var.u1, cov=cov, var.e=var.e,
eff.sizes=eff.sizes, fraction=fraction, log.grow=log.grow)
},
future.seed = TRUE
)
future::plan(future::sequential)  # Reset plan to avoid unexpected parallel behavior later
})
bfs
N
j
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
results
getpower_mis_mv <- function(attrition="weibull", params=c(.5,1),
m=100, N=100, t.points=c(0,1,2,3,4), var.u0=0.03,
var.u1=.1, var.e=.02, cov=0, eff.sizes=c(0, .5, .5),
fraction=1, log.grow=F, seed=NULL,
hypothesis="a<b<c", PMPthres=.9, BFthres=5){
if(!is.null(seed)) {set.seed(seed)}  # set user-specified seed for reproducibility
suppressWarnings({ # suppress warning "package 'future' was built under R version 4.4.3"
future::plan(future::multisession, workers = future::availableCores() - 1)  # Use all but one core
Ns <- rep(N, m)  # object to use lapply on with first argument for the function (N)
# Run simulation m times
bfs <- future.apply::future_lapply(
Ns,
function(ss){
getbf_mis_mv(ss,
attrition=attrition,
params=params, hypothesis=hypothesis, t.points=t.points,
var.u0=var.u0, var.u1=var.u1, cov=cov, var.e=var.e,
eff.sizes=eff.sizes, fraction=fraction, log.grow=log.grow)
},
future.seed = TRUE
)
future::plan(future::sequential)  # Reset plan to avoid unexpected parallel behavior later
})
# extract number of simplified models due to identification issues
prop_simplified <- mean(unlist(sapply(bfs, function(x) {x[4]})))
# extract BFs and PMPs
bfc <- sapply(bfs, function(x) {x[1]})
pmp <- sapply(bfs, function(x) {x[2]})
bf <- sapply(bfs, function(x) {x[3]})
power_bfc <- mean(bfc > BFthres)
power_pmp <- mean(pmp > PMPthres)
power_bf <- mean(bf > BFthres)
return(list(power_bfc=power_bfc,
power_pmp=power_pmp,
power_bf=power_bf,
prop_simplified=prop_simplified))
}
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
results
params
results$prop_simplified > 0
warning(sprintf("%.1f%% of models required simplification (independent random effects) due to high attrition",
prop_simplified * 100))
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%.1f%% of models required simplification (independent random effects) due to high attrition rate",
prop_simplified * 100))
}
prop_simplified
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%.1f%% of models required simplification (independent random effects) due to high attrition rate",
round(prop_simplified * 100)))
}
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%df%% of models required simplification (independent random effects) due to high attrition rate",
round(prop_simplified * 100)))
}
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate",
round(prop_simplified * 100)))
}
BayeSSD <- function(eta=.8, attrition="weibull", params=c(.5,1),
m=100, t.points=c(0,1,2,3,4), var.u0=0.01,
var.u1=.1, var.e=.01, cov=0, eff.sizes=c(0, .5, .8),
BFthres=5, fraction=1, log.grow=F, seed=NULL,
hypothesis="a<b<c", PMPthres=.9, sensitivity=F, tol=.001,
N_max=1000, N_min=30, method="bfc") {
# error and warning messages in case of incorrect input
if(eta<0 | eta>1) {stop("'eta' (the desired power level) must be between 0 and 1.")}
if(m%%1!=0 | m<1) {stop("'m' must be a positive integer.")}
if(!is.logical(log.grow)) {stop("'log.grow' must be either TRUE or FALSE.")}
if(is.logical(sensitivity)==F) {stop("'sensitivity' must be either TRUE or FALSE.")}
if(any(t.points<0)) {stop("all time points must be positive.")}
if(var.u0<0 | var.u1<0 | var.e<0) {stop("all variance components must be positive.")}
if(BFthres<0) {stop("'BFthres' must be positive.")}
if(fraction%%1!=0 | fraction<1) {stop("'fraction' must be a positive integer, b=fraction/N.")}
if(m<1000) {warning("Results with less than 1000 generated datasets per iteration can be unreliable.")}
if((method=="bf" | method=="BF") & (length(hypothesis)!=2)) {stop("Method 'bf' requires exactly two hypotheses.")}
start_time <- Sys.time()
if(!is.null(seed)) {set.seed(seed)}  # set user-specified seed for reproducibility
N <- list()
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
while(condition == F){
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(prop_simplified * 100)))
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == Nmin+1 | Nmax == Nmin) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f)\n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
}
devtools::document()
?BayeSSd
?BayeSSD
