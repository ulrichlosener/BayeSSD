`t:treat1` = zeros,
`t:treat2` = t.points)
# Construct D (variance-covariance matrix of random effects)
D <- Matrix::bdiag(lapply(reVar, function(x) as(Matrix::bdiag(x), "generalMatrix")))
# Precompute all possible subsets under attrition
row_indices <- lapply(n:1, function(k) if(k == n) 1:n else 1:k)
# Computation of V and W matrices
V_subsets <- lapply(row_indices, function(rows) {
Z_sub <- Z[rows, , drop = FALSE]
as(Z_sub %*% D %*% t(Z_sub) + sigma2 * Matrix::Diagonal(length(rows)), "CsparseMatrix")
})
W_subsets <- lapply(V_subsets, function(V) {
Matrix::Diagonal(x = diag(as.matrix(V)))
})
# Computation of inverses
inverses <- lapply(seq_along(V_subsets), function(i) {
list(
V_inv = solve(V_subsets[[i]]),
W_inv = solve(W_subsets[[i]])
)
})
# Initialize sum matrices
sum_mat <- sum_mat_indep <- matrix(0, 6, 6)
# Compute sum matrices under dependence and independence assumption
if(is.list(surviv) & length(surviv)>1){
# Backwards loop for each treatment group with unique survival pattern
res <- lapply(surviv, function(x) {
for (k in n:1) {
idx <- n - k + 1
rows <- row_indices[[idx]]
inv <- inverses[[idx]]
# Get subset matrices
X_wl_sub <- X_wl[rows, , drop = FALSE]
X_tau_sub <- X_tau[rows, , drop = FALSE]
X_interv_sub <- X_interv[rows, , drop = FALSE]
# Take sums for all three conditions
sum_mat <- sum_mat + x[k] * (
t(X_wl_sub) %*% inv$V_inv %*% X_wl_sub +
t(X_tau_sub) %*% inv$V_inv %*% X_tau_sub +
t(X_interv_sub) %*% inv$V_inv %*% X_interv_sub
)
sum_mat_indep <- sum_mat_indep + x[k] * (
t(X_wl_sub) %*% inv$W_inv %*% X_wl_sub +
t(X_tau_sub) %*% inv$W_inv %*% X_tau_sub +
t(X_interv_sub) %*% inv$W_inv %*% X_interv_sub
)
}
# Matrix solving with fallback to pseudoinverse
var_beta_hat <-  tryCatch(solve(sum_mat), error = function(e) MASS::ginv(sum_mat))
var_betahat_indep <-  tryCatch(solve(sum_mat_indep), error = function(e) MASS::ginv(sum_mat_indep))
# Compute N_eff
w <- var_betahat_indep / var_beta_hat
N_eff <- w * (N/3) * n # divide N by 3 because of 3 conditions
return(list(N_eff[2,2], N_eff[5,5], N_eff[6,6]))
})
return(list(N_eff_cond1 = res[[1]][1],
N_eff_cond2 = res[[2]][1],
N_eff_cond3 = res[[3]][1]
))
} else {
# same pattern for all three groups
for (k in n:1) {
idx <- n - k + 1
rows <- row_indices[[idx]]
inv <- inverses[[idx]]
# Get subset matrices
X_wl_sub <- X_wl[rows, , drop = FALSE]
X_tau_sub <- X_tau[rows, , drop = FALSE]
X_interv_sub <- X_interv[rows, , drop = FALSE]
# Take sums for all three conditions
sum_mat <- sum_mat + surviv[k] * (
t(X_wl_sub) %*% inv$V_inv %*% X_wl_sub +
t(X_tau_sub) %*% inv$V_inv %*% X_tau_sub +
t(X_interv_sub) %*% inv$V_inv %*% X_interv_sub
)
sum_mat_indep <- sum_mat_indep + surviv[k] * (
t(X_wl_sub) %*% inv$W_inv %*% X_wl_sub +
t(X_tau_sub) %*% inv$W_inv %*% X_tau_sub +
t(X_interv_sub) %*% inv$W_inv %*% X_interv_sub
)
}
# Matrix solving with fallback to pseudoinverse
var_beta_hat <- tryCatch(solve(sum_mat), error = function(e) MASS::ginv(sum_mat))
var_betahat_indep <- tryCatch(solve(sum_mat_indep), error = function(e) MASS::ginv(sum_mat_indep))
# Compute N_eff
w <- var_betahat_indep / var_beta_hat
N_eff <- w * N * n
return(list(N_eff_cond1 = N_eff[2,2]/3,
N_eff_cond2 = N_eff[5,5]/3,
N_eff_cond3 = N_eff[6,6]/3))
}
is.list(surviv) & length(surviv)>1
k
idx <- n - k + 1
idx
rows <- row_indices[[idx]]
rows
inv <- inverses[[idx]]
inv
# Get subset matrices
X_wl_sub <- X_wl[rows, , drop = FALSE]
X_wl_sub
X_tau_sub <- X_tau[rows, , drop = FALSE]
X_tau_sub
X_interv_sub <- X_interv[rows, , drop = FALSE]
X_interv_sub
# Take sums for all three conditions
sum_mat <- sum_mat + surviv[k] * (
t(X_wl_sub) %*% inv$V_inv %*% X_wl_sub +
t(X_tau_sub) %*% inv$V_inv %*% X_tau_sub +
t(X_interv_sub) %*% inv$V_inv %*% X_interv_sub
)
sum_mat
# Initialize sum matrices
sum_mat <- sum_mat_indep <- matrix(0, 6, 6)
sum_mat
surviv[k]
surviv
surviv
library(BayeSSD)
BayeSSD()
library(BayeSSD)
BayeSSD()
library(BayeSSD)
BayeSSD()
warnings()
n <- length(t.points)  # number of measurement occasions
# create time variable t
if(log.grow==F) {t <- rep(t.points, N) # if logarithmic growth is used, take log of t.points
} else {if(min(t.points)==0) {t <- rep(log(t.points+1), N)} else {t <- rep(log(t.points), N)} # if the first timepoint is zero, we add 1 to all timepoints because log(0) is undefined
}
# create time variable t
if(log.grow==F) {t <- rep(t.points, N) # if logarithmic growth is used, take log of t.points
} else {if(min(t.points)==0) {t <- rep(log(t.points+1), N)} else {t <- rep(log(t.points), N)} # if the first timepoint is zero, we add 1 to all timepoints because log(0) is undefined
}
t.prop <- t.points/max(t.points) # create rescaled time variable (from 0 to 1)
id <- rep(seq_len(N), each=n)  # create ID variable
treat <- as.character(gl(n=3, k=n, length=N*n, labels=c("a","b","c"))) # create treatment variable
dat0 <- data.frame(id, treat, t) # combine into data frame
dat0$treat <- factor(dat0$treat, levels = c("a", "b", "c")) # Forces "a" as reference
multinorm <- MASS::mvrnorm(n=2*N, mu=c(0,0), matrix(c(var.u0, cov, cov, var.u1), nrow=2, ncol=2)) # draw random effects
# make params into list of one vector
if (is.list(params)) {
params <- list(unlist(params, use.names = FALSE))
} else {
params <- list(params)
}
# Compute survival curves
if(any(attrition != F)){
surviv <- survival(attrition, params, t.points)
shifted_surviv <- lapply(surviv, function(x) {c(x[-1], NA)}) # drop first element and append NA to compute hazard
} else if(attrition==F){
surviv <- list(rep(1, n))
shifted_surviv <- c(surviv[-1], NA)
}
# compute hazard: (S_t - S_{t+1}) / S_t
hazard <- mapply(function(a, b) {(a - b) / a},
surviv,
shifted_surviv,
SIMPLIFY = FALSE)
# generate data under the research hypothesis
u0 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),1], each=n) # random intercepts
u1 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),2], each=n) # random slopes
e <- rnorm(N*n, 0, sqrt(var.e)) # error variance for H1
# Create treatment dummy variables
treat_TAU <- as.numeric(treat == "b")
treat_INT <- as.numeric(treat == "c")
beta1_WL <- unlist(eff.sizes[1]) * sqrt(var.u1)
beta2_TAU <- unlist(eff.sizes[2]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for b from effect size
beta3_INT <- unlist(eff.sizes[3]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for c from effect size
y <- beta1_WL*t + u0 + beta2_TAU*treat_TAU*t + beta3_INT*treat_INT*t + u1*t + e # create outcome variable y
if(attrition != F) {
dat <- data.frame(dat0, y, hazard = unlist(hazard))
suppressWarnings(dat$mis <- rbinom(n = nrow(dat), size = 1, prob = dat$hazard)) # suppress warning about NAs being produced
dat$mis <- unsplit(lapply(split(dat$mis, dat$id), function(x) {
if (any(x == 1, na.rm = TRUE)) {
first_mis <- which(x == 1)[1]  # Get first occurrence of 1
x[first_mis:length(x)] <- 1    # Set all subsequent to 1
}
x[is.na(x)] <- 0  # Treat NAs as 0 (non-missing)
x
}), dat$id)
dat$y[dat$mis == 1] <- NA
} else {
dat <- data.frame(dat0, y)
}
dat
# fit MLM to dataset
model <- lme4::lmer(formula = y ~ t + treat + t:treat + (1 + t | id), data = dat, REML=F, control = lme4::lmerControl(calc.derivs = F))  # fit MLM model under H1
est <- model@beta[c(2,5,6)] # extract estimates of beta2 and beta3 under H0
names(est) <- c("a", "b", "c")
sig_WL <- as.matrix(vcov(model)[2,2])  # extract variance of estimates under H0
sig_TAU <- as.matrix(vcov(model)[5,5])  # extract variance of estimates under H0
sig_INT <- as.matrix(vcov(model)[6,6])  # extract variance of estimates under H0
est
n <- length(t.points)  # number of measurement occasions
# create time variable t
if(log.grow==F) {t <- rep(t.points, N) # if logarithmic growth is used, take log of t.points
} else {if(min(t.points)==0) {t <- rep(log(t.points+1), N)} else {t <- rep(log(t.points), N)} # if the first timepoint is zero, we add 1 to all timepoints because log(0) is undefined
}
t.prop <- t.points/max(t.points) # create rescaled time variable (from 0 to 1)
id <- rep(seq_len(N), each=n)  # create ID variable
treat <- as.character(gl(n=3, k=n, length=N*n, labels=c("a","b","c"))) # create treatment variable
dat0 <- data.frame(id, treat, t) # combine into data frame
dat0$treat <- factor(dat0$treat, levels = c("a", "b", "c")) # Forces "a" as reference
multinorm <- MASS::mvrnorm(n=2*N, mu=c(0,0), matrix(c(var.u0, cov, cov, var.u1), nrow=2, ncol=2)) # draw random effects
# make params into list of one vector
if (is.list(params)) {
params <- list(unlist(params, use.names = FALSE))
} else {
params <- list(params)
}
# Compute survival curves
if(any(attrition != F)){
surviv <- survival(attrition, params, t.points)
shifted_surviv <- lapply(surviv, function(x) {c(x[-1], NA)}) # drop first element and append NA to compute hazard
} else if(attrition==F){
surviv <- list(rep(1, n))
shifted_surviv <- c(surviv[-1], NA)
}
# compute hazard: (S_t - S_{t+1}) / S_t
hazard <- mapply(function(a, b) {(a - b) / a},
surviv,
shifted_surviv,
SIMPLIFY = FALSE)
# generate data under the research hypothesis
u0 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),1], each=n) # random intercepts
u1 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),2], each=n) # random slopes
e <- rnorm(N*n, 0, sqrt(var.e)) # error variance for H1
# Create treatment dummy variables
treat_TAU <- as.numeric(treat == "b")
treat_INT <- as.numeric(treat == "c")
beta1_WL <- unlist(eff.sizes[1]) * sqrt(var.u1)
beta2_TAU <- unlist(eff.sizes[2]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for b from effect size
beta3_INT <- unlist(eff.sizes[3]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for c from effect size
y <- beta1_WL*t + u0 + beta2_TAU*treat_TAU*t + beta3_INT*treat_INT*t + u1*t + e # create outcome variable y
if(attrition != F) {
dat <- data.frame(dat0, y, hazard = unlist(hazard))
suppressWarnings(dat$mis <- rbinom(n = nrow(dat), size = 1, prob = dat$hazard)) # suppress warning about NAs being produced
dat$mis <- unsplit(lapply(split(dat$mis, dat$id), function(x) {
if (any(x == 1, na.rm = TRUE)) {
first_mis <- which(x == 1)[1]  # Get first occurrence of 1
x[first_mis:length(x)] <- 1    # Set all subsequent to 1
}
x[is.na(x)] <- 0  # Treat NAs as 0 (non-missing)
x
}), dat$id)
dat$y[dat$mis == 1] <- NA
} else {
dat <- data.frame(dat0, y)
}
# fit MLM to dataset
model <- lme4::lmer(formula = y ~ t + treat + t:treat + (1 + t | id), data = dat, REML=F, control = lme4::lmerControl(calc.derivs = F))  # fit MLM model under H1
est <- model@beta[c(2,5,6)]
est
n <- length(t.points)  # number of measurement occasions
# create time variable t
if(log.grow==F) {t <- rep(t.points, N) # if logarithmic growth is used, take log of t.points
} else {if(min(t.points)==0) {t <- rep(log(t.points+1), N)} else {t <- rep(log(t.points), N)} # if the first timepoint is zero, we add 1 to all timepoints because log(0) is undefined
}
t.prop <- t.points/max(t.points) # create rescaled time variable (from 0 to 1)
id <- rep(seq_len(N), each=n)  # create ID variable
treat <- as.character(gl(n=3, k=n, length=N*n, labels=c("a","b","c"))) # create treatment variable
dat0 <- data.frame(id, treat, t) # combine into data frame
dat0$treat <- factor(dat0$treat, levels = c("a", "b", "c")) # Forces "a" as reference
multinorm <- MASS::mvrnorm(n=2*N, mu=c(0,0), matrix(c(var.u0, cov, cov, var.u1), nrow=2, ncol=2)) # draw random effects
# make params into list of one vector
if (is.list(params)) {
params <- list(unlist(params, use.names = FALSE))
} else {
params <- list(params)
}
# Compute survival curves
if(any(attrition != F)){
surviv <- survival(attrition, params, t.points)
shifted_surviv <- lapply(surviv, function(x) {c(x[-1], NA)}) # drop first element and append NA to compute hazard
} else if(attrition==F){
surviv <- list(rep(1, n))
shifted_surviv <- c(surviv[-1], NA)
}
# compute hazard: (S_t - S_{t+1}) / S_t
hazard <- mapply(function(a, b) {(a - b) / a},
surviv,
shifted_surviv,
SIMPLIFY = FALSE)
# generate data under the research hypothesis
u0 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),1], each=n) # random intercepts
u1 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),2], each=n) # random slopes
e <- rnorm(N*n, 0, sqrt(var.e)) # error variance for H1
# Create treatment dummy variables
treat_TAU <- as.numeric(treat == "b")
treat_INT <- as.numeric(treat == "c")
beta1_WL <- unlist(eff.sizes[1]) * sqrt(var.u1)
beta2_TAU <- unlist(eff.sizes[2]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for b from effect size
beta3_INT <- unlist(eff.sizes[3]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for c from effect size
y <- beta1_WL*t + u0 + beta2_TAU*treat_TAU*t + beta3_INT*treat_INT*t + u1*t + e # create outcome variable y
if(attrition != F) {
dat <- data.frame(dat0, y, hazard = unlist(hazard))
suppressWarnings(dat$mis <- rbinom(n = nrow(dat), size = 1, prob = dat$hazard)) # suppress warning about NAs being produced
dat$mis <- unsplit(lapply(split(dat$mis, dat$id), function(x) {
if (any(x == 1, na.rm = TRUE)) {
first_mis <- which(x == 1)[1]  # Get first occurrence of 1
x[first_mis:length(x)] <- 1    # Set all subsequent to 1
}
x[is.na(x)] <- 0  # Treat NAs as 0 (non-missing)
x
}), dat$id)
dat$y[dat$mis == 1] <- NA
} else {
dat <- data.frame(dat0, y)
}
# fit MLM to dataset
model <- lme4::lmer(formula = y ~ t + treat + t:treat + (1 + t | id), data = dat, REML=F, control = lme4::lmerControl(calc.derivs = F))  # fit MLM model under H1
est <- model@beta[c(2,5,6)]
est
n <- length(t.points)  # number of measurement occasions
# create time variable t
if(log.grow==F) {t <- rep(t.points, N) # if logarithmic growth is used, take log of t.points
} else {if(min(t.points)==0) {t <- rep(log(t.points+1), N)} else {t <- rep(log(t.points), N)} # if the first timepoint is zero, we add 1 to all timepoints because log(0) is undefined
}
t.prop <- t.points/max(t.points) # create rescaled time variable (from 0 to 1)
id <- rep(seq_len(N), each=n)  # create ID variable
treat <- as.character(gl(n=3, k=n, length=N*n, labels=c("a","b","c"))) # create treatment variable
dat0 <- data.frame(id, treat, t) # combine into data frame
dat0$treat <- factor(dat0$treat, levels = c("a", "b", "c")) # Forces "a" as reference
multinorm <- MASS::mvrnorm(n=2*N, mu=c(0,0), matrix(c(var.u0, cov, cov, var.u1), nrow=2, ncol=2)) # draw random effects
# make params into list of one vector
if (is.list(params)) {
params <- list(unlist(params, use.names = FALSE))
} else {
params <- list(params)
}
# Compute survival curves
if(any(attrition != F)){
surviv <- survival(attrition, params, t.points)
shifted_surviv <- lapply(surviv, function(x) {c(x[-1], NA)}) # drop first element and append NA to compute hazard
} else if(attrition==F){
surviv <- list(rep(1, n))
shifted_surviv <- c(surviv[-1], NA)
}
# compute hazard: (S_t - S_{t+1}) / S_t
hazard <- mapply(function(a, b) {(a - b) / a},
surviv,
shifted_surviv,
SIMPLIFY = FALSE)
# generate data under the research hypothesis
u0 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),1], each=n) # random intercepts
u1 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),2], each=n) # random slopes
e <- rnorm(N*n, 0, sqrt(var.e)) # error variance for H1
# Create treatment dummy variables
treat_TAU <- as.numeric(treat == "b")
treat_INT <- as.numeric(treat == "c")
beta1_WL <- unlist(eff.sizes[1]) * sqrt(var.u1)
beta2_TAU <- unlist(eff.sizes[2]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for b from effect size
beta3_INT <- unlist(eff.sizes[3]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for c from effect size
y <- beta1_WL*t + u0 + beta2_TAU*treat_TAU*t + beta3_INT*treat_INT*t + u1*t + e # create outcome variable y
if(attrition != F) {
dat <- data.frame(dat0, y, hazard = unlist(hazard))
suppressWarnings(dat$mis <- rbinom(n = nrow(dat), size = 1, prob = dat$hazard)) # suppress warning about NAs being produced
dat$mis <- unsplit(lapply(split(dat$mis, dat$id), function(x) {
if (any(x == 1, na.rm = TRUE)) {
first_mis <- which(x == 1)[1]  # Get first occurrence of 1
x[first_mis:length(x)] <- 1    # Set all subsequent to 1
}
x[is.na(x)] <- 0  # Treat NAs as 0 (non-missing)
x
}), dat$id)
dat$y[dat$mis == 1] <- NA
} else {
dat <- data.frame(dat0, y)
}
# fit MLM to dataset
model <- lme4::lmer(formula = y ~ t + treat + t:treat + (1 + t | id), data = dat, REML=F, control = lme4::lmerControl(calc.derivs = F))  # fit MLM model under H1
est <- model@beta[c(2,5,6)]
est
n <- length(t.points)  # number of measurement occasions
# create time variable t
if(log.grow==F) {t <- rep(t.points, N) # if logarithmic growth is used, take log of t.points
} else {if(min(t.points)==0) {t <- rep(log(t.points+1), N)} else {t <- rep(log(t.points), N)} # if the first timepoint is zero, we add 1 to all timepoints because log(0) is undefined
}
t.prop <- t.points/max(t.points) # create rescaled time variable (from 0 to 1)
id <- rep(seq_len(N), each=n)  # create ID variable
treat <- as.character(gl(n=3, k=n, length=N*n, labels=c("a","b","c"))) # create treatment variable
dat0 <- data.frame(id, treat, t) # combine into data frame
dat0$treat <- factor(dat0$treat, levels = c("a", "b", "c")) # Forces "a" as reference
multinorm <- MASS::mvrnorm(n=2*N, mu=c(0,0), matrix(c(var.u0, cov, cov, var.u1), nrow=2, ncol=2)) # draw random effects
# make params into list of one vector
if (is.list(params)) {
params <- list(unlist(params, use.names = FALSE))
} else {
params <- list(params)
}
# Compute survival curves
if(any(attrition != F)){
surviv <- survival(attrition, params, t.points)
shifted_surviv <- lapply(surviv, function(x) {c(x[-1], NA)}) # drop first element and append NA to compute hazard
} else if(attrition==F){
surviv <- list(rep(1, n))
shifted_surviv <- c(surviv[-1], NA)
}
# compute hazard: (S_t - S_{t+1}) / S_t
hazard <- mapply(function(a, b) {(a - b) / a},
surviv,
shifted_surviv,
SIMPLIFY = FALSE)
# generate data under the research hypothesis
u0 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),1], each=n) # random intercepts
u1 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),2], each=n) # random slopes
e <- rnorm(N*n, 0, sqrt(var.e)) # error variance for H1
# Create treatment dummy variables
treat_TAU <- as.numeric(treat == "b")
treat_INT <- as.numeric(treat == "c")
beta1_WL <- unlist(eff.sizes[1]) * sqrt(var.u1)
beta2_TAU <- unlist(eff.sizes[2]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for b from effect size
beta3_INT <- unlist(eff.sizes[3]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for c from effect size
y <- beta1_WL*t + u0 + beta2_TAU*treat_TAU*t + beta3_INT*treat_INT*t + u1*t + e # create outcome variable y
if(attrition != F) {
dat <- data.frame(dat0, y, hazard = unlist(hazard))
suppressWarnings(dat$mis <- rbinom(n = nrow(dat), size = 1, prob = dat$hazard)) # suppress warning about NAs being produced
dat$mis <- unsplit(lapply(split(dat$mis, dat$id), function(x) {
if (any(x == 1, na.rm = TRUE)) {
first_mis <- which(x == 1)[1]  # Get first occurrence of 1
x[first_mis:length(x)] <- 1    # Set all subsequent to 1
}
x[is.na(x)] <- 0  # Treat NAs as 0 (non-missing)
x
}), dat$id)
dat$y[dat$mis == 1] <- NA
} else {
dat <- data.frame(dat0, y)
}
# fit MLM to dataset
model <- lme4::lmer(formula = y ~ t + treat + t:treat + (1 + t | id), data = dat, REML=F, control = lme4::lmerControl(calc.derivs = F))  # fit MLM model under H1
est <- model@beta[c(2,5,6)]
est
n <- length(t.points)  # number of measurement occasions
# create time variable t
if(log.grow==F) {t <- rep(t.points, N) # if logarithmic growth is used, take log of t.points
} else {if(min(t.points)==0) {t <- rep(log(t.points+1), N)} else {t <- rep(log(t.points), N)} # if the first timepoint is zero, we add 1 to all timepoints because log(0) is undefined
}
t.prop <- t.points/max(t.points) # create rescaled time variable (from 0 to 1)
id <- rep(seq_len(N), each=n)  # create ID variable
treat <- as.character(gl(n=3, k=n, length=N*n, labels=c("a","b","c"))) # create treatment variable
dat0 <- data.frame(id, treat, t) # combine into data frame
dat0$treat <- factor(dat0$treat, levels = c("a", "b", "c")) # Forces "a" as reference
multinorm <- MASS::mvrnorm(n=2*N, mu=c(0,0), matrix(c(var.u0, cov, cov, var.u1), nrow=2, ncol=2)) # draw random effects
# make params into list of one vector
if (is.list(params)) {
params <- list(unlist(params, use.names = FALSE))
} else {
params <- list(params)
}
# Compute survival curves
if(any(attrition != F)){
surviv <- survival(attrition, params, t.points)
shifted_surviv <- lapply(surviv, function(x) {c(x[-1], NA)}) # drop first element and append NA to compute hazard
} else if(attrition==F){
surviv <- list(rep(1, n))
shifted_surviv <- c(surviv[-1], NA)
}
# compute hazard: (S_t - S_{t+1}) / S_t
hazard <- mapply(function(a, b) {(a - b) / a},
surviv,
shifted_surviv,
SIMPLIFY = FALSE)
# generate data under the research hypothesis
u0 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),1], each=n) # random intercepts
u1 <- rep(multinorm[(nrow(multinorm)/2+1):(nrow(multinorm)),2], each=n) # random slopes
e <- rnorm(N*n, 0, sqrt(var.e)) # error variance for H1
# Create treatment dummy variables
treat_TAU <- as.numeric(treat == "b")
treat_INT <- as.numeric(treat == "c")
beta1_WL <- unlist(eff.sizes[1]) * sqrt(var.u1)
beta2_TAU <- unlist(eff.sizes[2]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for b from effect size
beta3_INT <- unlist(eff.sizes[3]) * sqrt(var.u1) + beta1_WL # create coefficient of interaction for c from effect size
y <- beta1_WL*t + u0 + beta2_TAU*treat_TAU*t + beta3_INT*treat_INT*t + u1*t + e # create outcome variable y
if(attrition != F) {
dat <- data.frame(dat0, y, hazard = unlist(hazard))
suppressWarnings(dat$mis <- rbinom(n = nrow(dat), size = 1, prob = dat$hazard)) # suppress warning about NAs being produced
dat$mis <- unsplit(lapply(split(dat$mis, dat$id), function(x) {
if (any(x == 1, na.rm = TRUE)) {
first_mis <- which(x == 1)[1]  # Get first occurrence of 1
x[first_mis:length(x)] <- 1    # Set all subsequent to 1
}
x[is.na(x)] <- 0  # Treat NAs as 0 (non-missing)
x
}), dat$id)
dat$y[dat$mis == 1] <- NA
} else {
dat <- data.frame(dat0, y)
}
# fit MLM to dataset
model <- lme4::lmer(formula = y ~ t + treat + t:treat + (1 + t | id), data = dat, REML=F, control = lme4::lmerControl(calc.derivs = F))  # fit MLM model under H1
est <- model@beta[c(2,5,6)]
est
if(attrition != F){
dat <- data.frame(dat0, y, hazard=unlist(hazard))
suppressWarnings(dat$mis <- rbinom(n=nrow(dat), size=1, prob=dat$hazard)) # suppress warning about NAs being produced
dat <- data.frame(dat %>% group_by(id) %>% mutate(mis = ifelse(cumany(mis == 1), 1, mis)))
dat$y[which(dat$mis==1)] <- NA
} else {
dat <- data.frame(dat0, y)
}
BayeSSD()
BayeSSD()
library(BayeSSD)
BayeSSD()
warnings()
install.packages("installr")
installr::updateR()  # On Windows
library(BayeSSD)
BayeSSD()
