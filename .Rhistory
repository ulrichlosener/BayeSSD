eff.sizes=eff.sizes, fraction=fraction, log.grow=log.grow)
},
future.seed = TRUE
)
future::plan(future::sequential)  # Reset plan to avoid unexpected parallel behavior later
})
bfs
# extract number of simplified models due to identification issues
prop_simplified <- mean(unlist(sapply(bfs, function(x) {x[4]})))
prop_simplified
# extract BFs and PMPs
bfc <- sapply(bfs, function(x) {x[1]})
pmp <- sapply(bfs, function(x) {x[2]})
bf <- sapply(bfs, function(x) {x[3]})
power_bfc <- mean(bfc > BFthres)
power_pmp <- mean(pmp > PMPthres)
power_bf <- mean(bf > BFthres)
power_bfc
power_pmp
power_bf
N <- 500
suppressWarnings({ # suppress warning "package 'future' was built under R version 4.4.3"
future::plan(future::multisession, workers = future::availableCores() - 1)  # Use all but one core
Ns <- rep(N, m)  # object to use lapply on with first argument for the function (N)
# Run simulation m times
bfs <- future.apply::future_lapply(
Ns,
function(ss){
getbf_mis_mv(ss,
attrition=attrition,
params=params, hypothesis=hypothesis, t.points=t.points,
var.u0=var.u0, var.u1=var.u1, cov=cov, var.e=var.e,
eff.sizes=eff.sizes, fraction=fraction, log.grow=log.grow)
},
future.seed = TRUE
)
future::plan(future::sequential)  # Reset plan to avoid unexpected parallel behavior later
})
prop_simplified <- mean(unlist(sapply(bfs, function(x) {x[4]})))
# extract BFs and PMPs
bfc <- sapply(bfs, function(x) {x[1]})
pmp <- sapply(bfs, function(x) {x[2]})
bf <- sapply(bfs, function(x) {x[3]})
power_bfc <- mean(bfc > BFthres)
power_pmp <- mean(pmp > PMPthres)
power_bf <- mean(bf > BFthres)
power_bfc
power_pmp
power_bf
N
j
j <- 1
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
results
N <- 100
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
results
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
method="bfc"
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
eta <- .8
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
pow
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(results$prop_simplified * 100)))
}
condition
condition <- FALSE    # condition initially FALSE until power criterion is reached
BayeSSD()
eta
attrition
params
m
t.points
var.u0
sensitivity
log.grow
var.u1
eff.sizes
N <- list()
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
while(condition == F){
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(results$prop_simplified * 100)))
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == Nmin+1 | Nmax == Nmin) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f)\n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
N_max
_max=1000
N_min=30
tol
tol=.001
while(condition == F){
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(results$prop_simplified * 100)))
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == Nmin+1 | Nmax == Nmin) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f)\n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
N
j
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
N <- list()
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
_max=1000
N_max=1000
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
while(condition == F){
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(results$prop_simplified * 100)))
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == Nmin+1 | Nmax == Nmin) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f)\n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
start_time <- Sys.time()
if(!is.null(seed)) {set.seed(seed)}  # set user-specified seed for reproducibility
N <- list()
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
while(condition == F){
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(results$prop_simplified * 100)))
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == Nmin+1 | Nmax == Nmin) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f)\n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
m
m <- 1000
start_time <- Sys.time()
if(!is.null(seed)) {set.seed(seed)}  # set user-specified seed for reproducibility
N <- list()
Nmin <- N_min            # (initial) minimal sample size
Nmax <- N_max         # (initial) maximum sample size
condition <- FALSE    # condition initially FALSE until power criterion is reached
j <- 1                # iteration counter
while(condition == F){
N[j] <- round((Nmin + Nmax)/2 - .1, digits = 0)  # current N is the mid point between Nmin and Nmax, rounded to the lower number
# generate data and store BFs
results <- getpower_mis_mv(attrition=attrition, params=params, m=m, N=unlist(N[j]),
log.grow=log.grow, fraction=fraction,
t.points=t.points, var.u0=var.u0, var.u1=var.u1,
cov=cov, var.e=var.e, eff.sizes=eff.sizes,
BFthres=BFthres, PMPthres=PMPthres, hypothesis=hypothesis)
# check if condition is met
if(method=="bfc" | method=="BFc" | method=="bf_c" | method=="BF_c"){
ifelse(results$power_bfc>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bfc
} else if(method=="pmp" | method=="PMP"){
ifelse(results$power_pmp>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_pmp
} else if(method=="bf" | method=="BF"){
ifelse(results$power_bf>=eta,
Nmax <- unlist(N[j]) - 1,
Nmin <- unlist(N[j]) + 1
)
pow <- results$power_bf
}
# Calculate time metrics
elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "mins"))
avg_time_per_iter <- elapsed / j
remaining_time <- avg_time_per_iter * (16 - j)  # max_iter = 16
# Print progress
cat(
sprintf("Iter %d: N = %d, Power = %.3f | Elapsed: %.1f minutes | Remaining: ~ %.1f minutes \n",
j, unlist(N[[j]]), pow, elapsed, remaining_time)
)
# Warn about simplified models due to too little observations
if(results$prop_simplified > 0) {
warning(sprintf("%d%% of models required simplification (independent random effects) due to high attrition rate.",
round(results$prop_simplified * 100)))
}
# if N increases by only 1 or f power level is very close to desired power level, condition is met and the algorithm stops
if ((N[j] == Nmin+1 | Nmax == Nmin) | round(abs(pow - eta), 8) <= tol) {
condition <- TRUE
total_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
cat(sprintf("\nConverged in %d iterations (%.1f minutes). Final N = %d (Power = %.3f)\n",
j, total_time, unlist(N[[j]]), pow))
}
# increase iteration by 1
j <- j+1
}
library(BayeSSD)
BayeSSD(eta = .8,
hypothesis = list("a=b=c"),
attrition = "nonparametric",
params = c(1,.799,.465),
m=1000,
t.points = c(0,4,8),
var.u0 =  1.854005,
var.u1 = 0.1265689,
var.e = 0.372619,
cov = -0.3485869,
eff.sizes = c(0.1624624, -0.0862778, -0.230364),
BFthres = 5,
fraction = 1,
sensitivity = F,
N_max = 2000,
method = "bfc")
BayeSSD(eta = .8,
hypothesis = list("a=b=c"),
attrition = "nonparametric",
params = c(1,.799,.465),
m=1000,
t.points = c(0,4,8),
var.u0 =  1.854005,
var.u1 = 0.1265689,
var.e = 0.372619,
cov = -0.3485869,
eff.sizes = c(0.1624624, -0.0862778, -0.230364),
BFthres = 5,
fraction = 1,
sensitivity = F,
N_max = 2000,
method = "bfc")
BayeSSD(eta = .8,
hypothesis = list("a=b=c"),
attrition = "nonparametric",
params = c(1,.799,.465),
m=1000,
t.points = c(0,4,8),
var.u0 =  1.854005,
var.u1 = 0.1265689,
var.e = 0.372619,
cov = -0.3485869,
eff.sizes = c(0.1624624, -0.0862778, -0.230364),
BFthres = 5,
fraction = 1,
sensitivity = F,
N_max = 2000,
method = "bfc")
library(BayeSSD)
BayeSSD(eta = .8,
hypothesis = list("a=b=c"),
attrition = "nonparametric",
params = c(1,.799,.465),
m=1000,
t.points = c(0,4,8),
var.u0 =  1.854005,
var.u1 = 0.1265689,
var.e = 0.372619,
cov = -0.3485869,
eff.sizes = c(0.1624624, -0.0862778, -0.230364),
BFthres = 5,
fraction = 1,
sensitivity = F,
N_max = 2000,
method = "bfc")
